---
User: 
Type: paper
Title: PromptShield: Deployable Detection for Prompt Injection Attacks
Summary: PromptShield, LLM’leri kullanarak **prompt injection** saldırılarını tespit eden bir sistemdir. Çok büyük bir veri kümesi ile eğitilir, bu sayede prompt injection saldırılarının **pattern**’larını (yapı ve dil kalıplarını) öğrenir. Gelen metinlerde şüpheli instruction’lar (örneğin “önceki talimatları görmezden gel” gibi) varsa bunları tespit etmeye çalışır.

Sistem, verilen metni **vektör embedding**’lerine çevirir ve bu embedding’leri kullanarak bir **olasılık** hesaplar (softmax probability). Daha sonra bu olasılıklar üzerinde yapılan matematiksel işlemlerle bir **eşik değer** (threshold) belirlenir. Bu eşik, modelin değerlendirme setinde hedeflenen **False Positive Rate (FPR)**’e göre hesaplanır; yani yanlış alarm oranını belirli bir seviyede tutacak şekilde ayarlanır.

Eğer P(malicious) bu threshold’un üzerindeyse girdi **malicious**, altında ise **safe** olarak işaretlenir. Genel olarak FPR’si düşüktür, fakat bazı eksikleri vardır. Örneğin, bir saldırgan öyle bir metin oluşturabilir ki matematiksel olarak hesaplanan skor threshold’un altında kalsın ve sistem saldırıyı görmesin. Ayrıca sistem şu an **görsel (image) tabanlı** girişlerde çalışmamaktadır.

